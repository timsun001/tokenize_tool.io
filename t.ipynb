{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4251637e-0ef9-4165-af77-2da9cfa6f409",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyQt5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjieba\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPyQt5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mQtWidgets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QApplication, QWidget, QVBoxLayout, QLabel, QLineEdit, QPushButton, QFileDialog\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask, render_template_string, request, jsonify\n\u001b[1;32m      7\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyQt5'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel, QLineEdit, QPushButton, QFileDialog\n",
    "from flask import Flask, render_template_string, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['SECRET_KEY'] = 'secret_key'\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 去除标点符号、空格、数字、英文字母\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "    # 限制字符长度为15\n",
    "    text = text[:20]\n",
    "    return text\n",
    "\n",
    "\n",
    "# 定义分词函数\n",
    "def tokenize(text):\n",
    "    words = jieba.lcut(text)\n",
    "    return words\n",
    "\n",
    "\n",
    "def process_data(raw_data_file, user_dict_file):\n",
    "    # 加载自定义分词字典\n",
    "    jieba.load_userdict(user_dict_file)\n",
    "\n",
    "    # 读取原始数据文件\n",
    "    data = pd.read_csv(raw_data_file)\n",
    "\n",
    "    result_set = []\n",
    "    items = data[['商品名称', '商品链接', '商品销量']][:2000]\n",
    "    # 数据预处理：去除标点符号、空格、数字、英文字母，并限制字符长度\n",
    "    items['商品简称'] = items['商品名称'].apply(lambda x: preprocess_text(x))\n",
    "\n",
    "    # 分词并聚合数据\n",
    "    word_counts = {}\n",
    "    word_sales = {}\n",
    "\n",
    "    for index, row in items.iterrows():\n",
    "        product_name = row['商品简称']\n",
    "        sales = row['商品销量']\n",
    "        words = tokenize(product_name)\n",
    "\n",
    "        for word in words:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "                word_sales[word] += sales\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "                word_sales[word] = sales\n",
    "\n",
    "    # 构建结果表\n",
    "    result = pd.DataFrame({'词': list(word_counts.keys()),\n",
    "                           '出现次数': list(word_counts.values()),\n",
    "                           '商品销量': list(word_sales.values())})\n",
    "    result['平均销量'] = result['商品销量'] / result['出现次数']\n",
    "    result_set.append(result)\n",
    "\n",
    "    result = pd.concat(result_set)\n",
    "\n",
    "    result.to_csv(\"result.csv\", encoding=\"gb18030\")\n",
    "    return result\n",
    "\n",
    "\n",
    "class MainWindow(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.raw_data_file = \"\"\n",
    "        self.user_dict_file = \"\"\n",
    "\n",
    "        self.layout = QVBoxLayout()\n",
    "        self.label_raw_data = QLabel(\"原始数据文件：\")\n",
    "        self.text_raw_data = QLineEdit()\n",
    "        self.button_raw_data = QPushButton(\"选择文件\")\n",
    "        self.button_raw_data.clicked.connect(self.select_raw_data_file)\n",
    "\n",
    "        self.label_user_dict = QLabel(\"自定义分词文件：\")\n",
    "        self.text_user_dict = QLineEdit()\n",
    "        self.button_user_dict = QPushButton(\"选择文件\")\n",
    "        self.button_user_dict.clicked.connect(self.select_user_dict_file)\n",
    "\n",
    "        self.button_tokenize = QPushButton(\"分词\")\n",
    "        self.button_tokenize.clicked.connect(self.tokenize_data)\n",
    "\n",
    "        self.layout.addWidget(self.label_raw_data)\n",
    "        self.layout.addWidget(self.text_raw_data)\n",
    "        self.layout.addWidget(self.button_raw_data)\n",
    "        self.layout.addWidget(self.label_user_dict)\n",
    "        self.layout.addWidget(self.text_user_dict)\n",
    "        self.layout.addWidget(self.button_user_dict)\n",
    "        self.layout.addWidget(self.button_tokenize)\n",
    "\n",
    "        self.setLayout(self.layout)\n",
    "\n",
    "    def select_raw_data_file(self):\n",
    "        file_dialog = QFileDialog()\n",
    "        file_dialog.setFileMode(QFileDialog.ExistingFile)\n",
    "        file_dialog.setNameFilter(\"CSV Files (*.csv)\")\n",
    "        if file_dialog.exec_():\n",
    "            filenames = file_dialog.selectedFiles()\n",
    "            self.raw_data_file = filenames[0]\n",
    "            self.text_raw_data.setText(self.raw_data_file)\n",
    "\n",
    "    def select_user_dict_file(self):\n",
    "        file_dialog = QFileDialog()\n",
    "        file_dialog.setFileMode(QFileDialog.ExistingFile)\n",
    "        file_dialog.setNameFilter(\"Text Files (*.txt)\")\n",
    "        if file_dialog.exec_():\n",
    "            filenames = file_dialog.selectedFiles()\n",
    "            self.user_dict_file = filenames[0]\n",
    "            self.text_user_dict.setText(self.user_dict_file)\n",
    "\n",
    "    def tokenize_data(self):\n",
    "        if self.raw_data_file != \"\" and self.user_dict_file != \"\":\n",
    "            result = process_data(self.raw_data_file, self.user_dict_file)\n",
    "            self.show_result(result)\n",
    "\n",
    "    def show_result(self, result):\n",
    "        html = result.to_html()\n",
    "        render_template = '''\n",
    "        <html>\n",
    "        <head>\n",
    "            <style>\n",
    "                table {\n",
    "                    border-collapse: collapse;\n",
    "                    width: 100%;\n",
    "                }\n",
    "                th, td {\n",
    "                    text-align: left;\n",
    "                    padding: 8px;\n",
    "                    border-bottom: 1px solid #ddd;\n",
    "                }\n",
    "                th {\n",
    "                    background-color: #f2f2f2;\n",
    "                }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            %s\n",
    "        </body>\n",
    "        </html>\n",
    "        '''\n",
    "        rendered = render_template_string(render_template % html)\n",
    "        with app.test_request_context('/'):\n",
    "            response = app.full_dispatch_request()\n",
    "        response.set_data(rendered)\n",
    "        response.headers['Content-Type'] = 'text/html'\n",
    "        response.headers['Content-Length'] = len(response.get_data())\n",
    "        response.headers['Access-Control-Allow-Origin'] = '*'\n",
    "        response.headers['Access-Control-Allow-Methods'] = 'GET'\n",
    "        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'\n",
    "        response.headers['Access-Control-Max-Age'] = '86400'\n",
    "        response.headers['Access-Control-Allow-Credentials'] = 'true'\n",
    "        response.headers['Access-Control-Expose-Headers'] = 'Content-Length'\n",
    "        response.headers['Access-Control-Allow-Headers'] = 'Range'\n",
    "        response.headers['Accept-Ranges'] = 'bytes'\n",
    "        response.headers['Content-Range'] = 'bytes 0-'\n",
    "        response.headers['Content-Disposition'] = 'inline'\n",
    "        return response\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return '''\n",
    "    <h1>分词工具</h1>\n",
    "    <p>请选择原始数据文件和自定义分词文件，然后点击“分词”按钮进行分词。</p>\n",
    "    <p>分词结果将显示在下方的表格中。</p>\n",
    "    '''\n",
    "\n",
    "\n",
    "@app.route('/process', methods=['POST'])\n",
    "def process():\n",
    "    raw_data_file = request.form['raw_data_file']\n",
    "    user_dict_file = request.form['user_dict_file']\n",
    "    result = process_data(raw_data_file, user_dict_file)\n",
    "    return jsonify(result.to_dict())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    window = QApplication([])\n",
    "    main_window = MainWindow()\n",
    "    main_window.show()\n",
    "\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e5a0c45-4cea-438f-aae9-51af030e7fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - pyqt5\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/osx-arm64\n",
      "  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/noarch\n",
      "  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/osx-arm64\n",
      "  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/noarch\n",
      "  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/osx-arm64\n",
      "  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/noarch\n",
      "  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/osx-arm64\n",
      "  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-arm64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-arm64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749e907-e2b4-46fc-8151-69904979f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 去除标点符号、空格、数字、英文字母\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "    # 限制字符长度为15\n",
    "    text = text[:20]\n",
    "    return text\n",
    "\n",
    "# 定义分词函数\n",
    "def tokenize(text):\n",
    "    words = jieba.lcut(text)\n",
    "    return words\n",
    "\n",
    "def process_data(raw_data_file, user_dict_file):\n",
    "    # 加载自定义分词字典\n",
    "    jieba.load_userdict(user_dict_file)\n",
    "\n",
    "    # 读取原始数据文件\n",
    "    data = pd.read_csv(raw_data_file)\n",
    "\n",
    "    result_set = []\n",
    "    items = data[['商品名称', '商品链接', '商品销量']][:2000]\n",
    "    # 数据预处理：去除标点符号、空格、数字、英文字母，并限制字符长度\n",
    "    items['商品简称'] = items['商品名称'].apply(lambda x: preprocess_text(x))\n",
    "\n",
    "    # 分词并聚合数据\n",
    "    word_counts = {}\n",
    "    word_sales = {}\n",
    "\n",
    "    for index, row in items.iterrows():\n",
    "        product_name = row['商品简称']\n",
    "        sales = row['商品销量']\n",
    "        words = tokenize(product_name)\n",
    "\n",
    "        for word in words:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "                word_sales[word] += sales\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "                word_sales[word] = sales\n",
    "\n",
    "    # 构建结果表\n",
    "    result = pd.DataFrame({'词': list(word_counts.keys()),\n",
    "                           '出现次数': list(word_counts.values()),\n",
    "                           '商品销量': list(word_sales.values())})\n",
    "    result['平均销量'] = result['商品销量'] / result['出现次数']\n",
    "    result_set.append(result)\n",
    "\n",
    "    result = pd.concat(result_set)\n",
    "\n",
    "    result.to_csv(\"result.csv\", encoding=\"gb18030\")\n",
    "    return result\n",
    "\n",
    "def select_raw_data_file():\n",
    "    raw_data_file = filedialog.askopenfilename(filetypes=[('CSV Files', '*.csv')])\n",
    "    entry_raw_data.delete(0, tk.END)\n",
    "    entry_raw_data.insert(0, raw_data_file)\n",
    "\n",
    "def select_user_dict_file():\n",
    "    user_dict_file = filedialog.askopenfilename(filetypes=[('Text Files', '*.txt')])\n",
    "    entry_user_dict.delete(0, tk.END)\n",
    "    entry_user_dict.insert(0, user_dict_file)\n",
    "\n",
    "def tokenize_data():\n",
    "    raw_data_file = entry_raw_data.get()\n",
    "    user_dict_file = entry_user_dict.get()\n",
    "    \n",
    "    if raw_data_file != \"\" and user_dict_file != \"\":\n",
    "        try:\n",
    "            result = process_data(raw_data_file, user_dict_file)\n",
    "            messagebox.showinfo(\"分词结果\", \"分词完成！结果已保存到result.csv文件。\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"错误\", str(e))\n",
    "    else:\n",
    "        messagebox.showwarning(\"警告\", \"请先选择原始数据文件和自定义分词文件。\")\n",
    "\n",
    "# 创建主窗口\n",
    "window = tk.Tk()\n",
    "window.title(\"分词工具\")\n",
    "\n",
    "# 创建文件选择框和按钮\n",
    "label_raw_data = tk.Label(window, text=\"原始数据文件：\")\n",
    "label_raw_data.grid(row=0, column=0, padx=10, pady=5, sticky=tk.W)\n",
    "entry_raw_data = tk.Entry(window, width=50)\n",
    "entry_raw_data.grid(row=0, column=1, padx=10, pady=5)\n",
    "button_select_raw_data = tk.Button(window, text=\"选择文件\", command=select_raw_data_file)\n",
    "button_select_raw_data.grid(row=0, column=2, padx=10, pady=5)\n",
    "\n",
    "label_user_dict = tk.Label(window, text=\"自定义分词文件：\")\n",
    "label_user_dict.grid(row=1, column=0, padx=10, pady=5, sticky=tk.W)\n",
    "entry_user_dict = tk.Entry(window, width=50)\n",
    "entry_user_dict.grid(row=1, column=1, padx=10, pady=5)\n",
    "button_select_user_dict = tk.Button(window, text=\"选择文件\", command=select_user_dict_file)\n",
    "button_select_user_dict.grid(row=1, column=2, padx=10, pady=5)\n",
    "\n",
    "button_tokenize = tk.Button(window, text=\"分词\", command=tokenize_data)\n",
    "button_tokenize.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529032fb-a9de-4328-8d9a-10ff5dac8f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433 INFO: PyInstaller: 5.13.0\n",
      "433 INFO: Python: 3.9.15 (conda)\n",
      "440 INFO: Platform: macOS-13.2.1-arm64-arm-64bit\n",
      "441 INFO: wrote /Users/suntian/GitHub/huitun/wordseg_tool/main.spec\n",
      "444 INFO: Extending PYTHONPATH with paths\n",
      "['/Users/suntian/GitHub/huitun/wordseg_tool']\n",
      "773 INFO: checking Analysis\n",
      "829 INFO: Building because hiddenimports changed\n",
      "829 INFO: Initializing module dependency graph...\n",
      "830 INFO: Caching module graph hooks...\n",
      "836 INFO: Analyzing base_library.zip ...\n",
      "1919 INFO: Loading module hook 'hook-encodings.py' from '/Users/suntian/opt/anaconda3/envs/paddle/lib/python3.9/site-packages/PyInstaller/hooks'...\n",
      "2703 INFO: Loading module hook 'hook-pickle.py' from '/Users/suntian/opt/anaconda3/envs/paddle/lib/python3.9/site-packages/PyInstaller/hooks'...\n",
      "3090 INFO: Loading module hook 'hook-heapq.py' from '/Users/suntian/opt/anaconda3/envs/paddle/lib/python3.9/site-packages/PyInstaller/hooks'...\n",
      "3357 INFO: Caching module dependency graph...\n",
      "3400 INFO: running Analysis Analysis-00.toc\n",
      "3403 INFO: Analyzing /Users/suntian/GitHub/huitun/wordseg_tool/main.py\n",
      "3403 INFO: Processing module hooks...\n",
      "3409 INFO: Looking for ctypes DLLs\n",
      "3410 INFO: Analyzing run-time hooks ...\n",
      "3413 INFO: Looking for dynamic libraries\n",
      "3804 INFO: Looking for eggs\n",
      "3804 INFO: Python library not among binary dependencies. Performing additional search...\n",
      "3806 INFO: Using Python library /Users/suntian/opt/anaconda3/envs/paddle/lib/libpython3.9.dylib\n",
      "3808 INFO: Warnings written to /Users/suntian/GitHub/huitun/wordseg_tool/build/main/warn-main.txt\n",
      "3815 INFO: Graph cross-reference written to /Users/suntian/GitHub/huitun/wordseg_tool/build/main/xref-main.html\n",
      "3818 INFO: checking PYZ\n",
      "3850 INFO: Building because toc changed\n",
      "3850 INFO: Building PYZ (ZlibArchive) /Users/suntian/GitHub/huitun/wordseg_tool/build/main/PYZ-00.pyz\n",
      "3941 INFO: Building PYZ (ZlibArchive) /Users/suntian/GitHub/huitun/wordseg_tool/build/main/PYZ-00.pyz completed successfully.\n",
      "3942 INFO: EXE target arch: arm64\n",
      "3942 INFO: Code signing identity: None\n",
      "3942 INFO: checking PKG\n",
      "3966 INFO: Building because toc changed\n",
      "3966 INFO: Building PKG (CArchive) main.pkg\n",
      "5351 INFO: Building PKG (CArchive) main.pkg completed successfully.\n",
      "5353 INFO: Bootloader /Users/suntian/opt/anaconda3/envs/paddle/lib/python3.9/site-packages/PyInstaller/bootloader/Darwin-64bit/runw\n",
      "5353 INFO: checking EXE\n",
      "5378 INFO: Building because console changed\n",
      "5378 INFO: Building EXE from EXE-00.toc\n",
      "5390 INFO: Copying bootloader EXE to /Users/suntian/GitHub/huitun/wordseg_tool/dist/main\n",
      "5390 INFO: Converting EXE to target arch (arm64)\n",
      "5409 INFO: Removing signature(s) from EXE\n",
      "5418 INFO: Appending PKG archive to EXE\n",
      "5420 INFO: Fixing EXE headers for code signing\n",
      "5424 INFO: Rewriting the executable's macOS SDK version (12.1.0) to match the SDK version of the Python library (11.0.0) in order to avoid inconsistent behavior and potential UI issues in the frozen application.\n",
      "5425 INFO: Re-signing the EXE\n",
      "5441 INFO: Building EXE from EXE-00.toc completed successfully.\n",
      "5443 INFO: checking BUNDLE\n",
      "5443 INFO: Building BUNDLE because BUNDLE-00.toc is non existent\n",
      "5443 INFO: Building BUNDLE BUNDLE-00.toc\n",
      "5445 INFO: Moving BUNDLE data files to Resource directory\n",
      "5445 INFO: Signing the BUNDLE...\n",
      "5462 INFO: Building BUNDLE BUNDLE-00.toc completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!pyinstaller main.py --onefile --noconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e545a48-a749-4ee9-9caa-178ff44afa9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
